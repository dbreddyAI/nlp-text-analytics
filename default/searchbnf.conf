[cleantext-command]
syntax = cleantext textfield=<field> (default_clean=<bool>)? (remove_urls=<bool>)? (remove_stopwords=<bool>)? (base_word=<bool>)? (base_type=<string>)? (mv=<bool>)? (pos_tagset=<string>)? (custom_stopwords=<comma_separated_string_list>)? (term_min_len=<int>)? (ngram_range=<int>-<int>)? (ngram_mix=<bool>)?
shortdesc = Tokenize and normalize text (remove punctuation, digits, change to base_word)
description = Tokenize and normalize text (remove punctuation, digits, change to base_word) \
    Different options result in better and slower cleaning. base_type="lemma_pos" being the \
    slowest option, base_type="lemma" assumes every word is a noun, which is faster but still \
    results in decent lemmatization. Many fields have a default already set, textfield is only \
    required field. By default results in a multi-valued field which is ready for used with \
    stats count by.
usage = public
example1 = * | cleantext textfield=sentence

[vader-command]
syntax = vader textfield=<field> (full_output=<bool>)?
shortdesc = Sentiment analysis using Valence Aware Dictionary and sEntiment Reasoner
description = Sentiment analysis using Valence Aware Dictionary and sEntiment Reasoner \
    Using option full_output will return scores for neutral, positive, and negative which \
    are the scores that make up the compound score (that is just returned as the field \
    "sentiment". Best to feed in uncleaned data as it takes into account capitalization \
    and punctuation.
usage = public
example1 = * | vader textfield=sentence
